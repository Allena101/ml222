{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#* IsActiveMember has a small negative correlation with Exited \n",
    "\n",
    "# Create a groupby\n",
    "counts = df.groupby(['IsActiveMember', 'Exited']).size().unstack()\n",
    "\n",
    "# Define the X-labels\n",
    "labels = ['Inactive Member', 'Active Member']\n",
    "\n",
    "# Plot a grouped bar chart\n",
    "counts.plot(kind='bar', stacked=False)\n",
    "\n",
    "# Set labels and title\n",
    "plt.xlabel('')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Comparison of IsActiveMember and Exited')\n",
    "plt.xticks(range(len(labels)), labels, rotation=0)\n",
    "plt.legend(labels=['Remained', 'Exited'])\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "#* Looks like a rather significant pattern of Active Members being less likely to exit\n",
    "# Still , would help alot with insight if we knew what constituted active and not-active membership"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#* Set Balance max to 300_000\n",
    "\n",
    "# Create a sample DataFrame\n",
    "data = {'values': [0, 500, 1500, 2000, 300000]}\n",
    "\n",
    "# Define the bins\n",
    "bins = [0, 1, 1000, 10000]\n",
    "\n",
    "# Bin the 'values' column\n",
    "df['binned'] = pd.cut(df['Balance'], bins=bins, right=False)\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "print(df)\n",
    "# df['bin'] = pd.cut(df['Balance'], [0, 1, 50, 100,200,300000])\n",
    "df['bin'] = pd.cut(df['Balance'], [-1, 0, 1, 50, 100, 200, 300000])\n",
    "\n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming your data is in the 'another_column' column of the DataFrame\n",
    "another_column_subset = df['Balance'].values.reshape(-1, 1)\n",
    "\n",
    "# Create a KBinsDiscretizer object with 5 bins and the quantile strategy\n",
    "discretizer = KBinsDiscretizer(n_bins=5, encode='ordinal', strategy='quantile')\n",
    "\n",
    "# Fit and transform the data using the discretizer\n",
    "another_column_binned = discretizer.fit_transform(another_column_subset)\n",
    "\n",
    "# Assign the discretized values to a new column in the DataFrame\n",
    "df['BalanceQuant'] = another_column_binned.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "tax_brackets = {\n",
    "    'France': [(0, 10225), (10226, 26070), (26071, 74545), (74546, 160336), (160337, float('inf'))], # For 2022\n",
    "    'Germany': [(0, 10347), (10909, 15999), (16000, 62809), (62810, 277825), (277826, float('inf'))], # For 2023\n",
    "    'Spain': [(0, 12450), (12451, 20200), (20201, 35200), (35201, 100000), (100001, float('inf'))], # For 2021. Spain has 6 brackets, so we are combining the highest 2\n",
    "}\n",
    "\n",
    "def get_tax_bracket(country, salary):\n",
    "    tax_ranges = tax_brackets[country]\n",
    "    for index, tax_range in enumerate(tax_ranges):\n",
    "        if tax_range[0] <= salary <= tax_range[1]:\n",
    "            return index\n",
    "    return None\n",
    "\n",
    "df['taxBracket'] = df.apply(lambda row: get_tax_bracket(row['Country'], row['EstimatedSalary']), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#! This is freqeuncy encoding\n",
    "\n",
    "# Calculate the frequency of occurrence for each value in the 'Surname' column\n",
    "value_frequencies = df['Surname'].value_counts()\n",
    "\n",
    "# Sort the values based on their frequency in descending order\n",
    "sorted_values = value_frequencies.index\n",
    "\n",
    "# Assign ordinal values to the sorted values\n",
    "ordinal_values = range(len(sorted_values))\n",
    "\n",
    "# Create a dictionary mapping the sorted values to their ordinal values\n",
    "encoding_dict = dict(zip(sorted_values, ordinal_values))\n",
    "\n",
    "# Use the dictionary to map the 'Surname' column values to their ordinal values in a new column\n",
    "df['SurnameOrdinal'] = df['Surname'].map(encoding_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "osborne_rows = df[df['Surname'] == 'Smith']\n",
    "print(len(osborne_rows))\n",
    "osborne_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a pipline (if you have time) for unprocessed pediction data\n",
    "# Training phase\n",
    "# Step 1: Train clustering algorithm on training data\n",
    "kmeans = KMeans(n_clusters=3)\n",
    "kmeans.fit(training_data)\n",
    "\n",
    "# Step 2: Add cluster labels as a new feature to the training data\n",
    "training_data['Cluster'] = kmeans.labels_\n",
    "\n",
    "# Step 3: Train your model using the training data, including the cluster feature\n",
    "model.fit(training_data, target_variable)\n",
    "\n",
    "# Prediction phase\n",
    "# Step 4: Prepare new data for prediction\n",
    "new_data = preprocess(new_data)  # Apply the same preprocessing steps as used for training\n",
    "new_clusters = kmeans.predict(new_data)  # Obtain cluster labels for new data\n",
    "new_data['Cluster'] = new_clusters  # Add cluster labels as a new feature\n",
    "\n",
    "# Make predictions using the trained model\n",
    "predictions = model.predict(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "\n",
    "# Define the model\n",
    "model_krs = Sequential()\n",
    "model_krs.add(Dense(1024, input_shape=(X_train.shape[1],), activation='relu'))\n",
    "model_krs.add(Dropout(0.2))\n",
    "model_krs.add(Dense(1024, activation='relu'))\n",
    "model_krs.add(Dropout(0.2))\n",
    "model_krs.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model_krs.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Print the model summary\n",
    "model_krs.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = model_krs.evaluate(X_train, y_train, verbose=False)\n",
    "print(\"Training Score: {:.4f}\".format(accuracy[0]))\n",
    "print(\"Training Accuracy: {:.4f}\".format(accuracy[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(fit_keras):\n",
    "    acc = fit_keras.history['accuracy']\n",
    "    val_acc = fit_keras.history['val_accuracy']\n",
    "    loss = fit_keras.history['loss']\n",
    "    val_loss = fit_keras.history['val_loss']\n",
    "    x = range(1, len(acc) + 1)\n",
    "\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(x, acc, 'b', label='Training acc')\n",
    "    plt.plot(x, val_acc, 'r', label='Testing acc')\n",
    "    plt.title('Training and Testing accuracy')\n",
    "    plt.legend()\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(x, loss, 'b', label='Training loss')\n",
    "    plt.plot(x, val_loss, 'r', label='Testing loss')\n",
    "    plt.title('Training and Testing loss')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('target', TargetEncoder(), continuous_features),\n",
    "        ('scaler', StandardScaler(), continuous_features),\n",
    "        ('ordinal', 'passthrough', ordinal_features),\n",
    "        ('cluster', 'passthrough', cluster_features),\n",
    "        ('categorical', 'passthrough', categorical_features)      \n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
