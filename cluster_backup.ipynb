{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/ageron/handson-ml2/master/datasets/housing/housing.csv'\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_long = df[['latitude', 'longitude']]\n",
    "lat, longg = df.latitude, df.longitude\n",
    "X = lat_long.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.metrics import silhouette_score as ss\n",
    "import itertools\n",
    "\n",
    "\n",
    "epsilons = np.linspace(0.01, 1, num=15)\n",
    "min_samples = np.arange(2, 20, step=3)\n",
    "combinations = list(itertools.product(epsilons, min_samples))\n",
    "N = len(combinations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores_and_labels(combinations, X):\n",
    "  scores = []\n",
    "  all_labels_list = []\n",
    "\n",
    "  for i, (eps, num_samples) in enumerate(combinations):\n",
    "    dbscan_cluster_model = DBSCAN(eps=eps, min_samples=num_samples).fit(X)\n",
    "    labels = dbscan_cluster_model.labels_\n",
    "    labels_set = set(labels)\n",
    "    num_clusters = len(labels_set)\n",
    "    if -1 in labels_set:\n",
    "      num_clusters -= 1\n",
    "    \n",
    "    if (num_clusters < 2) or (num_clusters > 50):\n",
    "      scores.append(-10)\n",
    "      all_labels_list.append('bad')\n",
    "      c = (eps, num_samples)\n",
    "      print(f\"Combination {c} on iteration {i+1} of {N} has {num_clusters} clusters. Moving on\")\n",
    "      continue\n",
    "    \n",
    "    scores.append(ss(X, labels))\n",
    "    all_labels_list.append(labels)\n",
    "    print(f\"Index: {i}, Score: {scores[-1]}, Labels: {all_labels_list[-1]}, NumClusters: {num_clusters}\")\n",
    "\n",
    "  best_index = np.argmax(scores)\n",
    "  best_parameters = combinations[best_index]\n",
    "  best_labels = all_labels_list[best_index]\n",
    "  best_score = scores[best_index]\n",
    "\n",
    "  return {'best_epsilon': best_parameters[0],\n",
    "          'best_min_samples': best_parameters[1], \n",
    "          'best_labels': best_labels,\n",
    "          'best_score': best_score}\n",
    "\n",
    "best_dict = get_scores_and_labels(combinations, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best_dict)\n",
    "df['cluster'] = best_dict['best_labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "\n",
    "continuous_features = X_train_comb[['Tenure', 'NumOfProducts', 'CreditScore', 'Age', 'Balance', 'EstimatedSalary', 'PointsEarned']]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(continuous_features)\n",
    "\n",
    "silhouette_scores = []\n",
    "best_score = -1\n",
    "best_clusters = 0\n",
    "\n",
    "for n_clusters in range(2, 10):\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init='auto')\n",
    "\n",
    "    kmeans.fit(scaled_features)\n",
    "    cluster_labels = kmeans.labels_\n",
    "    silhouette_avg = silhouette_score(scaled_features, cluster_labels)\n",
    "    \n",
    "    silhouette_scores.append(silhouette_avg)\n",
    "    \n",
    "    if silhouette_avg > best_score:\n",
    "        best_score = silhouette_avg\n",
    "        best_clusters = n_clusters\n",
    "\n",
    "print(\"Best number of clusters:\", best_clusters)\n",
    "\n",
    "# Plotting the silhouette scores\n",
    "plt.plot(range(2, 10), silhouette_scores, marker='o')\n",
    "plt.xlabel(\"Number of Clusters\")\n",
    "plt.ylabel(\"Silhouette Score\")\n",
    "plt.title(\"Silhouette Score for Different Numbers of Clusters\")\n",
    "plt.show()\n",
    "\n",
    "#* This does not look promising, but we will go with 2 (maybe try 3-4 later) since it works with our binary classification problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import BayesianGaussianMixture\n",
    "from sklearn.metrics import silhouette_score\n",
    "import numpy as np\n",
    "\n",
    "# Assuming 'continuous_features' contains the continuous features from your dataframe\n",
    "\n",
    "# Scale the continuous features\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(continuous_features)\n",
    "\n",
    "# Define the range of number of clusters to consider\n",
    "n_clusters_range = range(2, 10)\n",
    "\n",
    "# Initialize variables to store silhouette scores and BIC values\n",
    "silhouette_scores = []\n",
    "bic_values = []\n",
    "\n",
    "# Iterate over different numbers of clusters\n",
    "for n_clusters in n_clusters_range:\n",
    "    # Fit the Bayesian Gaussian Mixture model\n",
    "    bgm = BayesianGaussianMixture(n_components=n_clusters, random_state=42)\n",
    "    bgm.fit(scaled_features)\n",
    "    \n",
    "    # Get cluster labels\n",
    "    cluster_labels = bgm.predict(scaled_features)\n",
    "    \n",
    "    # Calculate silhouette score\n",
    "    silhouette_avg = silhouette_score(scaled_features, cluster_labels)\n",
    "    silhouette_scores.append(silhouette_avg)\n",
    "    \n",
    "    # Calculate BIC value manually\n",
    "    log_likelihood = bgm.score(scaled_features)\n",
    "    n_samples, n_features = scaled_features.shape\n",
    "    n_parameters = n_clusters * (n_features + 1) + (n_clusters - 1)\n",
    "    bic = -2 * log_likelihood + n_parameters * np.log(n_samples)\n",
    "    bic_values.append(bic)\n",
    "\n",
    "# Plotting the silhouette scores\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(n_clusters_range, silhouette_scores, marker='o')\n",
    "plt.xlabel('Number of Clusters')\n",
    "plt.ylabel('Silhouette Score')\n",
    "plt.title('Silhouette Score vs. Number of Clusters')\n",
    "plt.show()\n",
    "\n",
    "# Plotting the BIC values\n",
    "plt.plot(n_clusters_range, bic_values, marker='o')\n",
    "plt.xlabel('Number of Clusters')\n",
    "plt.ylabel('BIC Value')\n",
    "plt.title('BIC Value vs. Number of Clusters')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_comb['test10'] = X_train_comb.CardTypeOrd / X_train_comb.NumOfProducts  0.070721\n",
    "X_train_comb['test11'] = X_train_comb.SurnameOrd / X_train_comb.IsActiveMember  0.013738\n",
    "X_train_comb['test5'] = X_train_comb.EstimatedSalary / X_train_comb.SurnameOrd  0.231549\n",
    "X_train_comb['tes10'] = X_train_comb.SatisfactionScore / X_train_comb.NumOfProducts 0.072405\n",
    "X_train_comb['tes10'] = X_train_comb.Tenure / X_train_comb.NumOfProducts    0.066692\n",
    "X_train_comb['test3'] = X_train_comb.Age / X_train_comb.GenderBinary    0.298647\n",
    "X_train_comb['tes10'] = X_train_comb.Age / X_train_comb.NumOfProducts   0.280828 # dont use\n",
    "X_train_comb['test3'] = X_train_comb.Balance / X_train_comb.GenderBinary    0.130356\n",
    "X_train_comb['test9'] = X_train_comb.Balance / X_train_comb.CreditScore     0.124030\n",
    "X_train_comb['test5'] = X_train_comb.GenderBinary / X_train_comb.SurnameOrd     0.214261\n",
    "X_train_comb['tes10'] = X_train_comb.GenderBinary / X_train_comb.NumOfProducts  0.137544\n",
    "X_train_comb['tes11'] = X_train_comb.GenderBinary / X_train_comb.IsActiveMember     0.110281\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
